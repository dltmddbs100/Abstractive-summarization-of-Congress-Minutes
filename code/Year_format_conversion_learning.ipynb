{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Year format conversion learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3BwJwQuCHQeR1UZmghq2T"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdBDUXZ69bd-"
      },
      "source": [
        "# Year format conversion learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Dense, Bidirectional, LSTM, RepeatVector\n",
        "from keras.models import Sequential\n",
        "\n",
        "from utils import CharacterTable, vectorization, train_val_split, model_inference, fitting_visualize\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "training_size = 50000\n",
        "\n",
        "# Maximum length of Answer\n",
        "maxlen = 20"
      ],
      "metadata": {
        "id": "eCCAZ1czfIO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_D22Z8FCLVf"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq56P1sI_QSG"
      },
      "source": [
        "# Generate the 'month' string to be used\n",
        "month=['january','february','march','april','may','june','july','august','september','october','november','december']\n",
        "\n",
        "# A dictionary mapping the corresponding 'month' to a number\n",
        "month_to_ind=dict((c,i+1) for i,c in enumerate(month))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVcscyA5_1oY"
      },
      "source": [
        "# Generate answer data matching the date in character format\n",
        "# Create a date in three formats\n",
        "def data_generation(size):\n",
        "  questions=[]\n",
        "  answers=[]\n",
        "\n",
        "  for i in range(size):\n",
        "    seed = np.random.randint(0,3)\n",
        "    \n",
        "    if seed==0:\n",
        "      q = np.random.choice(month)+' '+str(np.random.randint(1,32))+'th, '+str(np.random.randint(1900,2022))\n",
        "      a = q.split()[2]+'-'+str(month_to_ind[q.split()[0]])+'-'+q.split()[1][:-3]\n",
        "\n",
        "    if seed==1:\n",
        "      q = str(np.random.randint(1900,2022))+' '+np.random.choice(month)+' '+str(np.random.randint(1,32))+'th'\n",
        "      a = q.split()[0]+'-'+str(month_to_ind[q.split()[1]])+'-'+q.split()[2][:-2]\n",
        "\n",
        "    if seed==2:\n",
        "      q = str(np.random.randint(1,32))+'th '+np.random.choice(month)+' '+str(np.random.randint(1900,2022))\n",
        "      a = q.split()[2]+'-'+str(month_to_ind[q.split()[1]])+'-'+q.split()[0][:-2]\n",
        "    \n",
        "    q += ' '*(20-len(q))\n",
        "    a += ' '*(10-len(a))\n",
        "\n",
        "    questions.append(q)\n",
        "    answers.append(a)\n",
        "\n",
        "  return questions, answers "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oIV5ovUBuok",
        "outputId": "f8f9968b-ebef-4959-d224-9d4d3470c46e"
      },
      "source": [
        "questions, answers = data_generation(training_size)\n",
        "\n",
        "print('Question Samples:\\n',questions[:5],'\\n')\n",
        "print('Answer Samples:\\n',answers[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Samples:\n",
            " ['october 19th, 1932  ', 'december 21th, 1915 ', '3th april 2003      ', '11th september 1946 ', '1966 december 4th   '] \n",
            "\n",
            "Answer Samples:\n",
            " ['1932-10-19', '1915-12-21', '2003-4-3  ', '1946-9-11 ', '1966-12-4 ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X078Vml4XomA"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEjDZsTmS0Z1"
      },
      "source": [
        "# The calculated number is 3 or 4 digits, and there are cases where ' ' is included, so the string of ' ' is also considered\n",
        "chars='0123456789-abcdefghijklmnopqrstuvwxyz, '\n",
        "ctable=CharacterTable(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8aRnquOTaXY",
        "outputId": "5c1041cd-859c-4d91-f387-f749048a359e"
      },
      "source": [
        "x, y = vectorization(questions, answers, chars, maxlen, 10, ctable)\n",
        "\n",
        "print(\"x shape\", x.shape)\n",
        "print(\"y shape\", y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape (50000, 20, 39)\n",
            "y shape (50000, 10, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcXXjSgoUL9g",
        "outputId": "79dbc41a-6b74-4a76-b344-667f8d13110a"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_val_split(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "(45000, 20, 39)\n",
            "(45000, 10, 39) \n",
            "\n",
            "Validation Data:\n",
            "(5000, 20, 39)\n",
            "(5000, 10, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEdmaCPUYjKg",
        "outputId": "a48ab197-5c99-49b2-fdc4-bcb73604bd21"
      },
      "source": [
        "print('Question:', questions[53],'\\n')\n",
        "print('Question:', answers[53],'\\n')\n",
        "\n",
        "print('Encoded Question:\\n\\n', x_train[53],'\\n')\n",
        "print('Encoded Answer:\\n\\n', y_train[53])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 2006 november 7th    \n",
            "\n",
            "Question: 2006-11-7  \n",
            "\n",
            "Encoded Question:\n",
            "\n",
            " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
            "\n",
            "Encoded Answer:\n",
            "\n",
            " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10jOiTCjY1VX"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJv6130AY1AH"
      },
      "source": [
        "# Build Bidirectional LSTM Sequence Model\n",
        "def bd_lstm_model(num_layers):\n",
        "  model=Sequential()\n",
        "  model.add(Bidirectional(LSTM(128),input_shape=(maxlen, len(chars))))\n",
        "  model.add(RepeatVector(10)) # convert because target value has 10 rows\n",
        "  for _ in range(num_layers):\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "  model.add(Dense(len(chars),activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model=bd_lstm_model(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEyxYV8IbhZ9",
        "outputId": "50e0ef4a-71f9-4329-b252-3e3d8b3ff03b"
      },
      "source": [
        "epochs=5\n",
        "batch_size=32\n",
        "\n",
        "fitting_visualize(x_train, y_train, x_val, y_val, model, epochs, batch_size, ctable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 43s 8ms/step - loss: 1.4250 - acc: 0.5501 - val_loss: 0.3716 - val_acc: 0.8615\n",
            "Q may 25th, 1935       T 1935-5-25  x 1955-5-25 \n",
            "Q march 24th, 1910     T 1910-3-24  x 1900-3-24 \n",
            "Q 1915 december 18th   T 1915-12-18 x 1911-12-18\n",
            "Q 26th january 1943    T 1943-1-26  x 1944-1-26 \n",
            "Q 23th april 1955      T 1955-4-23  v 1955-4-23 \n",
            "Q december 8th, 1909   T 1909-12-8  x 1900-12-8 \n",
            "Q november 17th, 1968  T 1968-11-17 x 1966-11-17\n",
            "Q july 11th, 1907      T 1907-7-11  x 1917-7-11 \n",
            "Q 2th september 1985   T 1985-9-2   x 1955-9-2  \n",
            "Q 30th june 1990       T 1990-6-30  v 1990-6-30 \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.2006 - acc: 0.9183 - val_loss: 0.0837 - val_acc: 0.9660\n",
            "Q 2014 december 10th   T 2014-12-10 v 2014-12-10\n",
            "Q 14th february 2006   T 2006-2-14  v 2006-2-14 \n",
            "Q november 7th, 1938   T 1938-11-7  x 1988-11-7 \n",
            "Q 1968 november 30th   T 1968-11-30 x 1988-11-30\n",
            "Q 1905 september 11th  T 1905-9-11  v 1905-9-11 \n",
            "Q january 7th, 1993    T 1993-1-7   v 1993-1-7  \n",
            "Q september 6th, 2021  T 2021-9-6   x 2011-9-6  \n",
            "Q march 31th, 2012     T 2012-3-31  x 2011-3-31 \n",
            "Q 1976 february 23th   T 1976-2-23  x 1966-2-23 \n",
            "Q september 24th, 2005 T 2005-9-24  v 2005-9-24 \n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0401 - acc: 0.9885 - val_loss: 0.0058 - val_acc: 0.9999\n",
            "Q 1949 july 21th       T 1949-7-21  v 1949-7-21 \n",
            "Q october 31th, 1967   T 1967-10-31 v 1967-10-31\n",
            "Q august 25th, 2016    T 2016-8-25  v 2016-8-25 \n",
            "Q 4th december 1912    T 1912-12-4  v 1912-12-4 \n",
            "Q 27th may 1912        T 1912-5-27  v 1912-5-27 \n",
            "Q october 9th, 1936    T 1936-10-9  v 1936-10-9 \n",
            "Q 11th january 1980    T 1980-1-11  v 1980-1-11 \n",
            "Q 1949 june 20th       T 1949-6-20  v 1949-6-20 \n",
            "Q 1932 june 24th       T 1932-6-24  v 1932-6-24 \n",
            "Q april 13th, 2008     T 2008-4-13  v 2008-4-13 \n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Q 23th february 1996   T 1996-2-23  v 1996-2-23 \n",
            "Q september 3th, 1941  T 1941-9-3   v 1941-9-3  \n",
            "Q 1919 february 12th   T 1919-2-12  v 1919-2-12 \n",
            "Q 1979 august 27th     T 1979-8-27  v 1979-8-27 \n",
            "Q july 18th, 1966      T 1966-7-18  v 1966-7-18 \n",
            "Q 7th june 1934        T 1934-6-7   v 1934-6-7  \n",
            "Q april 1th, 1942      T 1942-4-1   v 1942-4-1  \n",
            "Q january 17th, 1926   T 1926-1-17  v 1926-1-17 \n",
            "Q 1928 january 8th     T 1928-1-8   v 1928-1-8  \n",
            "Q march 25th, 1992     T 1992-3-25  v 1992-3-25 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 10s 7ms/step - loss: 8.2634e-04 - acc: 1.0000 - val_loss: 5.1715e-04 - val_acc: 1.0000\n",
            "Q september 10th, 1904 T 1904-9-10  v 1904-9-10 \n",
            "Q 21th august 1991     T 1991-8-21  v 1991-8-21 \n",
            "Q 1929 march 6th       T 1929-3-6   v 1929-3-6  \n",
            "Q april 27th, 1932     T 1932-4-27  v 1932-4-27 \n",
            "Q 1903 april 30th      T 1903-4-30  v 1903-4-30 \n",
            "Q 2020 december 9th    T 2020-12-9  v 2020-12-9 \n",
            "Q january 1th, 1987    T 1987-1-1   v 1987-1-1  \n",
            "Q june 14th, 1984      T 1984-6-14  v 1984-6-14 \n",
            "Q 25th june 1938       T 1938-6-25  v 1938-6-25 \n",
            "Q 30th june 1933       T 1933-6-30  v 1933-6-30 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRER4eJLdSif"
      },
      "source": [
        "# Build Basic LSTM Sequence Model\n",
        "def bd_lstm_model(num_layers):\n",
        "  model=Sequential()\n",
        "  model.add(LSTM(128,input_shape=(maxlen, len(chars))))\n",
        "  model.add(RepeatVector(10)) # convert because target value has 10 rows\n",
        "  for _ in range(num_layers):\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "  model.add(Dense(len(chars),activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model=bd_lstm_model(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXL7yke6dZ9v",
        "outputId": "0b784427-7814-4481-bd9e-bdcaddb7c9da"
      },
      "source": [
        "epochs=5\n",
        "batch_size=32\n",
        "\n",
        "fitting_visualize(x_train, y_train, x_val, y_val, model, epochs, batch_size, ctable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 11s 6ms/step - loss: 1.4633 - acc: 0.5337 - val_loss: 0.4621 - val_acc: 0.8241\n",
            "Q february 7th, 1952   T 1952-2-7   x 1922-2-5  \n",
            "Q september 4th, 1930  T 1930-9-4   x 1900-9-4  \n",
            "Q 1942 may 15th        T 1942-5-15  x 1955-5-25 \n",
            "Q august 15th, 2000    T 2000-8-15  x 2008-8-18 \n",
            "Q september 6th, 1992  T 1992-9-6   x 1996-9-9  \n",
            "Q 1974 april 29th      T 1974-4-29  x 1944-4-24 \n",
            "Q october 23th, 1944   T 1944-10-23 v 1944-10-23\n",
            "Q february 26th, 1996  T 1996-2-26  v 1996-2-26 \n",
            "Q 1932 april 26th      T 1932-4-26  x 1922-4-22 \n",
            "Q 7th march 1955       T 1955-3-7   x 1955-5-5  \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2765 - acc: 0.8851 - val_loss: 0.1973 - val_acc: 0.9141\n",
            "Q 1989 march 3th       T 1989-3-3   v 1989-3-3  \n",
            "Q 1960 december 1th    T 1960-12-1  v 1960-12-1 \n",
            "Q july 1th, 1964       T 1964-7-1   x 1966-7-1  \n",
            "Q january 21th, 1927   T 1927-1-21  x 1927-1-22 \n",
            "Q 1928 may 29th        T 1928-5-29  x 1922-5-29 \n",
            "Q 1987 february 23th   T 1987-2-23  x 1988-2-23 \n",
            "Q december 5th, 1924   T 1924-12-5  x 1922-12-5 \n",
            "Q september 12th, 2013 T 2013-9-12  x 2013-9-11 \n",
            "Q 2012 july 23th       T 2012-7-23  x 2022-7-23 \n",
            "Q 26th february 1986   T 1986-2-26  x 1988-2-26 \n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0703 - acc: 0.9745 - val_loss: 0.0160 - val_acc: 0.9984\n",
            "Q december 11th, 1946  T 1946-12-11 v 1946-12-11\n",
            "Q 8th july 1979        T 1979-7-8   v 1979-7-8  \n",
            "Q 28th december 2000   T 2000-12-28 v 2000-12-28\n",
            "Q june 7th, 1945       T 1945-6-7   v 1945-6-7  \n",
            "Q 1964 may 17th        T 1964-5-17  v 1964-5-17 \n",
            "Q 21th september 1990  T 1990-9-21  v 1990-9-21 \n",
            "Q may 15th, 1999       T 1999-5-15  v 1999-5-15 \n",
            "Q 23th november 1997   T 1997-11-23 v 1997-11-23\n",
            "Q 24th november 1967   T 1967-11-24 v 1967-11-24\n",
            "Q 24th july 2018       T 2018-7-24  v 2018-7-24 \n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0156 - acc: 0.9967 - val_loss: 0.1006 - val_acc: 0.9664\n",
            "Q january 26th, 1995   T 1995-1-26  v 1995-1-26 \n",
            "Q 14th march 2017      T 2017-3-14  v 2017-3-14 \n",
            "Q 1924 february 29th   T 1924-2-29  v 1924-2-29 \n",
            "Q 1915 december 18th   T 1915-12-18 v 1915-12-18\n",
            "Q june 16th, 1938      T 1938-6-16  x 1938-6-1  \n",
            "Q february 21th, 1992  T 1992-2-21  v 1992-2-21 \n",
            "Q 3th may 1996         T 1996-5-3   v 1996-5-3  \n",
            "Q 27th april 1983      T 1983-4-27  v 1983-4-27 \n",
            "Q 2th august 2018      T 2018-8-2   v 2018-8-2  \n",
            "Q 1921 september 30th  T 1921-9-30  x 2011-9-30 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0036 - acc: 0.9994 - val_loss: 8.0006e-04 - val_acc: 1.0000\n",
            "Q 16th august 1916     T 1916-8-16  v 1916-8-16 \n",
            "Q 1985 june 25th       T 1985-6-25  v 1985-6-25 \n",
            "Q january 4th, 2014    T 2014-1-4   v 2014-1-4  \n",
            "Q 2003 june 2th        T 2003-6-2   v 2003-6-2  \n",
            "Q 14th may 1975        T 1975-5-14  v 1975-5-14 \n",
            "Q 11th october 1965    T 1965-10-11 v 1965-10-11\n",
            "Q november 12th, 1966  T 1966-11-12 v 1966-11-12\n",
            "Q 31th december 2004   T 2004-12-31 v 2004-12-31\n",
            "Q august 29th, 1920    T 1920-8-29  v 1920-8-29 \n",
            "Q february 25th, 1928  T 1928-2-25  v 1928-2-25 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "5qP_Yx4la3Kx",
        "outputId": "395ab94a-86ef-406a-aa2d-24f003043b90"
      },
      "source": [
        "model_inference('april 5th 2012', model, ctable).strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2012-4-5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjTEbenQfZ3X",
        "outputId": "ba88d1e8-22e0-4d2b-8374-0e7d82934c86"
      },
      "source": [
        "print('Inaccurate Test 1:',model_inference('2013 sepstemer 25th').strip())\n",
        "print('Inaccurate Test 2:',model_inference('2019 julqy 29th').strip())\n",
        "print('Inaccurate Test 3:',model_inference('15th octobe, 1944').strip())\n",
        "print('Inaccurate Test 4:',model_inference('marh, 22th 1903').strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inaccurate Test 1: 2013-9-25\n",
            "Inaccurate Test 2: 2019-7-29\n",
            "Inaccurate Test 3: 1944-10-15\n",
            "Inaccurate Test 4: 1903-3-2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}